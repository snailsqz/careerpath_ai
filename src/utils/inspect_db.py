from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
import os
import pandas as pd

# ‡πÉ‡∏ä‡πâ Model ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏™‡∏£‡πâ‡∏≤‡∏á DB (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å! ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô)
EMBEDDING_MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

def get_db_path():
    try:
        current_path = os.path.dirname(os.path.abspath(__file__))
    except NameError:
        current_path = os.getcwd()
    
    # ‡πÄ‡∏î‡∏¥‡∏ô‡∏´‡∏≤ folder vector_store
    project_root = current_path
    while True:
        if os.path.exists(os.path.join(project_root, 'data')):
            break
        parent = os.path.dirname(project_root)
        if parent == project_root:
            project_root = os.getcwd()
            break
        project_root = parent
        
    return os.path.join(project_root, 'vector_store')

def inspect():
    db_path = get_db_path()
    print(f"üìÇ Database Path: {db_path}")
    
    if not os.path.exists(db_path):
        print("‚ùå Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå Database")
        return

    try:
        # 1. ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ DB
        embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)
        db = Chroma(persist_directory=db_path, embedding_function=embedding_model)
        
        # 2. ‡πÄ‡∏ä‡πá‡∏Ñ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Count)
        # Chroma ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô collection (default ‡∏ä‡∏∑‡πà‡∏≠ 'langchain')
        collection = db._collection 
        count = collection.count()
        
        print(f"\nüìä Total Documents: {count:,} items")
        print("-" * 50)

        if count == 0:
            print("‚ö†Ô∏è Database ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤")
            return

        # 3. ‡∏Ç‡∏≠‡∏î‡∏π‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ 5 ‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å (Peek)
        print("üëÄ Peeking at first 5 items:\n")
        
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡∏Å‡∏°‡∏≤ (limit 5)
        data = collection.get(limit=5)
        
        # data ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô dictionary ‡∏ó‡∏µ‡πà‡∏°‡∏µ keys: ['ids', 'embeddings', 'documents', 'metadatas']
        ids = data['ids']
        metadatas = data['metadatas']
        documents = data['documents']

        for i in range(len(ids)):
            print(f"[{i+1}] ID: {ids[i]}")
            print(f"    Title: {metadatas[i].get('title', 'N/A')}")
            print(f"    Source: {metadatas[i].get('source', 'N/A')}")
            print(f"    Category: {metadatas[i].get('category', 'N/A')}")
            print(f"    Content Preview: {documents[i][:100]}...") # ‡πÇ‡∏ä‡∏ß‡πå‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ 100 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÅ‡∏£‡∏Å
            print("-" * 30)

        # 4. (‡πÅ‡∏ñ‡∏°) ‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° Source
        # ‡∏î‡∏∂‡∏á Metadata ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏°‡∏≤ Group by (‡∏£‡∏∞‡∏ß‡∏±‡∏á‡∏ä‡πâ‡∏≤‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏¢‡∏≠‡∏∞‡∏°‡∏≤‡∏Å)
        if count < 10000: # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏¢‡∏≠‡∏∞‡∏°‡∏≤‡∏Å‡∏Ñ‡πà‡∏≠‡∏¢‡∏ó‡∏≥
            print("\nüìà Statistics by Source:")
            all_data = collection.get()
            df = pd.DataFrame(all_data['metadatas'])
            if 'source' in df.columns:
                print(df['source'].value_counts().to_markdown())
            else:
                print("No 'source' field found in metadata.")

    except Exception as e:
        print(f"‚ùå Error: {e}")

if __name__ == "__main__":
    inspect()